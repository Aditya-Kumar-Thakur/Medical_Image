{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1f56aca-02cb-425c-81ad-abcf12934412",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "import librosa.display\n",
    "\n",
    "import plotly.express as px\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "from librosa import feature, amplitude_to_db, load\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense , Activation , Dropout\n",
    "\n",
    "pd.plotting.register_matplotlib_converters()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9522872-910e-460a-8de3-80450b0dcf8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1/136 files (0.74%)\n",
      "Processed 2/136 files (1.47%)\n",
      "Processed 3/136 files (2.21%)\n",
      "Processed 4/136 files (2.94%)\n",
      "Processed 5/136 files (3.68%)\n",
      "Processed 6/136 files (4.41%)\n",
      "Processed 7/136 files (5.15%)\n",
      "Processed 8/136 files (5.88%)\n",
      "Processed 9/136 files (6.62%)\n",
      "Processed 10/136 files (7.35%)\n",
      "Processed 11/136 files (8.09%)\n",
      "Processed 12/136 files (8.82%)\n",
      "Processed 13/136 files (9.56%)\n",
      "Processed 14/136 files (10.29%)\n",
      "Processed 15/136 files (11.03%)\n",
      "Processed 16/136 files (11.76%)\n",
      "Processed 17/136 files (12.50%)\n",
      "Processed 18/136 files (13.24%)\n",
      "Processed 19/136 files (13.97%)\n",
      "Processed 20/136 files (14.71%)\n",
      "Processed 21/136 files (15.44%)\n",
      "Processed 22/136 files (16.18%)\n",
      "Processed 23/136 files (16.91%)\n",
      "Processed 24/136 files (17.65%)\n",
      "Processed 25/136 files (18.38%)\n",
      "Processed 26/136 files (19.12%)\n",
      "Processed 27/136 files (19.85%)\n",
      "Processed 28/136 files (20.59%)\n",
      "Processed 29/136 files (21.32%)\n",
      "Processed 30/136 files (22.06%)\n",
      "Processed 31/136 files (22.79%)\n",
      "Processed 32/136 files (23.53%)\n",
      "Processed 33/136 files (24.26%)\n",
      "Processed 34/136 files (25.00%)\n",
      "Processed 35/136 files (25.74%)\n",
      "Processed 36/136 files (26.47%)\n",
      "Processed 37/136 files (27.21%)\n",
      "Processed 38/136 files (27.94%)\n",
      "Processed 39/136 files (28.68%)\n",
      "Processed 40/136 files (29.41%)\n",
      "Processed 41/136 files (30.15%)\n",
      "Processed 42/136 files (30.88%)\n",
      "Processed 43/136 files (31.62%)\n",
      "Processed 44/136 files (32.35%)\n",
      "Processed 45/136 files (33.09%)\n",
      "Processed 46/136 files (33.82%)\n",
      "Processed 47/136 files (34.56%)\n",
      "Processed 48/136 files (35.29%)\n",
      "Processed 49/136 files (36.03%)\n",
      "Processed 50/136 files (36.76%)\n",
      "Processed 51/136 files (37.50%)\n",
      "Processed 52/136 files (38.24%)\n",
      "Processed 53/136 files (38.97%)\n",
      "Processed 54/136 files (39.71%)\n",
      "Processed 55/136 files (40.44%)\n",
      "Processed 56/136 files (41.18%)\n",
      "Processed 57/136 files (41.91%)\n",
      "Processed 58/136 files (42.65%)\n",
      "Processed 59/136 files (43.38%)\n",
      "Processed 60/136 files (44.12%)\n",
      "Processed 61/136 files (44.85%)\n",
      "Processed 62/136 files (45.59%)\n",
      "Processed 63/136 files (46.32%)\n",
      "Processed 64/136 files (47.06%)\n",
      "Processed 65/136 files (47.79%)\n",
      "Processed 66/136 files (48.53%)\n",
      "Processed 67/136 files (49.26%)\n",
      "Processed 68/136 files (50.00%)\n",
      "Processed 69/136 files (50.74%)\n",
      "Processed 70/136 files (51.47%)\n",
      "Processed 71/136 files (52.21%)\n",
      "Processed 72/136 files (52.94%)\n",
      "Processed 73/136 files (53.68%)\n",
      "Processed 74/136 files (54.41%)\n",
      "Processed 75/136 files (55.15%)\n",
      "Processed 76/136 files (55.88%)\n",
      "Processed 77/136 files (56.62%)\n",
      "Processed 78/136 files (57.35%)\n",
      "Processed 79/136 files (58.09%)\n",
      "Processed 80/136 files (58.82%)\n",
      "Processed 81/136 files (59.56%)\n",
      "Processed 82/136 files (60.29%)\n",
      "Processed 83/136 files (61.03%)\n",
      "Processed 84/136 files (61.76%)\n",
      "Processed 85/136 files (62.50%)\n",
      "Processed 86/136 files (63.24%)\n",
      "Processed 87/136 files (63.97%)\n",
      "Processed 88/136 files (64.71%)\n",
      "Processed 89/136 files (65.44%)\n",
      "Processed 90/136 files (66.18%)\n",
      "Processed 91/136 files (66.91%)\n",
      "Processed 92/136 files (67.65%)\n",
      "Processed 93/136 files (68.38%)\n",
      "Processed 94/136 files (69.12%)\n",
      "Processed 95/136 files (69.85%)\n",
      "Processed 96/136 files (70.59%)\n",
      "Processed 97/136 files (71.32%)\n",
      "Processed 98/136 files (72.06%)\n",
      "Processed 99/136 files (72.79%)\n",
      "Processed 100/136 files (73.53%)\n",
      "Processed 101/136 files (74.26%)\n",
      "Processed 102/136 files (75.00%)\n",
      "Processed 103/136 files (75.74%)\n",
      "Processed 104/136 files (76.47%)\n",
      "Processed 105/136 files (77.21%)\n",
      "Processed 106/136 files (77.94%)\n",
      "Processed 107/136 files (78.68%)\n",
      "Processed 108/136 files (79.41%)\n",
      "Processed 109/136 files (80.15%)\n",
      "Processed 110/136 files (80.88%)\n",
      "Processed 111/136 files (81.62%)\n",
      "Processed 112/136 files (82.35%)\n",
      "Processed 113/136 files (83.09%)\n",
      "Processed 114/136 files (83.82%)\n",
      "Processed 115/136 files (84.56%)\n",
      "Processed 116/136 files (85.29%)\n",
      "Processed 117/136 files (86.03%)\n",
      "Processed 118/136 files (86.76%)\n",
      "Processed 119/136 files (87.50%)\n",
      "Processed 120/136 files (88.24%)\n",
      "Processed 121/136 files (88.97%)\n",
      "Processed 122/136 files (89.71%)\n",
      "Processed 123/136 files (90.44%)\n",
      "Processed 124/136 files (91.18%)\n",
      "Processed 125/136 files (91.91%)\n",
      "Processed 126/136 files (92.65%)\n",
      "Processed 127/136 files (93.38%)\n",
      "Processed 128/136 files (94.12%)\n",
      "Processed 129/136 files (94.85%)\n",
      "Processed 130/136 files (95.59%)\n",
      "Processed 131/136 files (96.32%)\n",
      "Processed 132/136 files (97.06%)\n",
      "Processed 133/136 files (97.79%)\n",
      "Processed 134/136 files (98.53%)\n",
      "Processed 135/136 files (99.26%)\n",
      "Processed 136/136 files (100.00%)\n",
      "\n",
      "âœ… All files processed. Mean MFCCs saved to mfcc_means_Control_hop_length.csv\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Function to extract mean MFCC features\n",
    "def extract_mean_mfcc(audio_file, n_mfcc=13, frame_length_ms=25, hop_length_ms=10):\n",
    "    \"\"\"\n",
    "    Extracts MFCC features from an audio file and computes the mean across frames.\n",
    "    Returns the mean MFCC features as a list.\n",
    "    \"\"\"\n",
    "    # Load the audio file\n",
    "    y, sr = librosa.load(audio_file, sr=None)  \n",
    "\n",
    "    # Compute hop length and FFT window size\n",
    "    hop_length = int((hop_length_ms / 1000) * sr)  \n",
    "    n_fft = int((frame_length_ms / 1000) * sr)    \n",
    "\n",
    "    # Extract MFCCs\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc, hop_length=hop_length, n_fft=n_fft)\n",
    "\n",
    "    # Compute the mean of MFCCs across time frames\n",
    "    mean_mfccs = np.mean(mfccs, axis=1)\n",
    "\n",
    "    return mean_mfccs\n",
    "\n",
    "# Function to process all audio files in a folder for multiple frame lengths\n",
    "def process_audio_folder(input_folder, output_csv=\"mfcc_means.csv\"):\n",
    "    \"\"\"\n",
    "    Processes all audio files in the input folder for different frame lengths,\n",
    "    extracts mean MFCCs, and saves results to a CSV.\n",
    "    \"\"\"\n",
    "    # Get all audio files in the folder\n",
    "    audio_files = [f for f in os.listdir(input_folder) if f.endswith(('.wav', '.mp3'))]\n",
    "    total_files = len(audio_files)\n",
    "    \n",
    "    if total_files == 0:\n",
    "        print(\"No audio files found in the folder!\")\n",
    "        return\n",
    "    \n",
    "    # List to store results\n",
    "    mfcc_results = []\n",
    "\n",
    "    # Process each audio file\n",
    "    for i, audio_file in enumerate(audio_files):\n",
    "        audio_path = os.path.join(input_folder, audio_file)\n",
    "        \n",
    "        #for hop_length in hop_lengths:\n",
    "            mean_mfcc = extract_mean_mfcc(audio_path, hop_length_ms)\n",
    "            \n",
    "            # Append results with filename and hop length\n",
    "            mfcc_result.append([audio_file, hop_length] + mean_mfcc.tolist())\n",
    "\n",
    "        # Display progress\n",
    "        print(f\"Processed {i + 1}/{total_files} files ({(i + 1) / total_files * 100:.2f}%)\")\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    column_name = [\"Filename\"] + [f\"MFCC_{i+1}\" for i in range(len(mean_mfccs))]\n",
    "    mfcc_df = pd.DataFrame(mfcc_results, column)\n",
    "\n",
    "    # Save to CSV\n",
    "    mfcc_df.to_csv(output_csv, index=False)\n",
    "    print(f\"\\nâœ… All files processed. Mean MFCCs saved to {output_csv}\")\n",
    "\n",
    "# Define input folder containing audio files\n",
    "input_folder = r\"C:\\Users\\adity\\OneDrive\\Desktop\\Speech Sample\\Dementia\"  # Replace with your actual folder path\n",
    "output_file = \"mfcc_means_Dementia_default.csv\"  # Output file\n",
    "\n",
    "# Process all files for multiple frame lengths and save mean MFCCs\n",
    "process_audio_folder(input_folder, output_csv=output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "552e2abf-c78f-4139-a041-b9a81f287fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged CSV file saved as 'merged_mfcc_default.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define file paths\n",
    "file1 = \"mfcc_means_Control_default.csv\"  # Replace with your actual file path\n",
    "file2 = \"mfcc_means_Dementia_default.csv\"  # Replace with your actual file path\n",
    "\n",
    "# Read both CSV files\n",
    "df1 = pd.read_csv(file1)\n",
    "df2 = pd.read_csv(file2)\n",
    "\n",
    "# Add an output column: 0 for the first file, 1 for the second\n",
    "df1[\"output\"] = 0\n",
    "df2[\"output\"] = 1\n",
    "\n",
    "# Merge the data\n",
    "merged_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "# Save the merged CSV\n",
    "merged_df.to_csv(\"merged_mfcc_default.csv\", index=False)\n",
    "\n",
    "print(\"Merged CSV file saved as 'merged_mfcc_default.csv'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b73da25-8753-46d6-9684-c7abefbe1105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1/136 files (0.74%)\n",
      "Processed 2/136 files (1.47%)\n",
      "Processed 3/136 files (2.21%)\n",
      "Processed 4/136 files (2.94%)\n",
      "Processed 5/136 files (3.68%)\n",
      "Processed 6/136 files (4.41%)\n",
      "Processed 7/136 files (5.15%)\n",
      "Processed 8/136 files (5.88%)\n",
      "Processed 9/136 files (6.62%)\n",
      "Processed 10/136 files (7.35%)\n",
      "Processed 11/136 files (8.09%)\n",
      "Processed 12/136 files (8.82%)\n",
      "Processed 13/136 files (9.56%)\n",
      "Processed 14/136 files (10.29%)\n",
      "Processed 15/136 files (11.03%)\n",
      "Processed 16/136 files (11.76%)\n",
      "Processed 17/136 files (12.50%)\n",
      "Processed 18/136 files (13.24%)\n",
      "Processed 19/136 files (13.97%)\n",
      "Processed 20/136 files (14.71%)\n",
      "Processed 21/136 files (15.44%)\n",
      "Processed 22/136 files (16.18%)\n",
      "Processed 23/136 files (16.91%)\n",
      "Processed 24/136 files (17.65%)\n",
      "Processed 25/136 files (18.38%)\n",
      "Processed 26/136 files (19.12%)\n",
      "Processed 27/136 files (19.85%)\n",
      "Processed 28/136 files (20.59%)\n",
      "Processed 29/136 files (21.32%)\n",
      "Processed 30/136 files (22.06%)\n",
      "Processed 31/136 files (22.79%)\n",
      "Processed 32/136 files (23.53%)\n",
      "Processed 33/136 files (24.26%)\n",
      "Processed 34/136 files (25.00%)\n",
      "Processed 35/136 files (25.74%)\n",
      "Processed 36/136 files (26.47%)\n",
      "Processed 37/136 files (27.21%)\n",
      "Processed 38/136 files (27.94%)\n",
      "Processed 39/136 files (28.68%)\n",
      "Processed 40/136 files (29.41%)\n",
      "Processed 41/136 files (30.15%)\n",
      "Processed 42/136 files (30.88%)\n",
      "Processed 43/136 files (31.62%)\n",
      "Processed 44/136 files (32.35%)\n",
      "Processed 45/136 files (33.09%)\n",
      "Processed 46/136 files (33.82%)\n",
      "Processed 47/136 files (34.56%)\n",
      "Processed 48/136 files (35.29%)\n",
      "Processed 49/136 files (36.03%)\n",
      "Processed 50/136 files (36.76%)\n",
      "Processed 51/136 files (37.50%)\n",
      "Processed 52/136 files (38.24%)\n",
      "Processed 53/136 files (38.97%)\n",
      "Processed 54/136 files (39.71%)\n",
      "Processed 55/136 files (40.44%)\n",
      "Processed 56/136 files (41.18%)\n",
      "Processed 57/136 files (41.91%)\n",
      "Processed 58/136 files (42.65%)\n",
      "Processed 59/136 files (43.38%)\n",
      "Processed 60/136 files (44.12%)\n",
      "Processed 61/136 files (44.85%)\n",
      "Processed 62/136 files (45.59%)\n",
      "Processed 63/136 files (46.32%)\n",
      "Processed 64/136 files (47.06%)\n",
      "Processed 65/136 files (47.79%)\n",
      "Processed 66/136 files (48.53%)\n",
      "Processed 67/136 files (49.26%)\n",
      "Processed 68/136 files (50.00%)\n",
      "Processed 69/136 files (50.74%)\n",
      "Processed 70/136 files (51.47%)\n",
      "Processed 71/136 files (52.21%)\n",
      "Processed 72/136 files (52.94%)\n",
      "Processed 73/136 files (53.68%)\n",
      "Processed 74/136 files (54.41%)\n",
      "Processed 75/136 files (55.15%)\n",
      "Processed 76/136 files (55.88%)\n",
      "Processed 77/136 files (56.62%)\n",
      "Processed 78/136 files (57.35%)\n",
      "Processed 79/136 files (58.09%)\n",
      "Processed 80/136 files (58.82%)\n",
      "Processed 81/136 files (59.56%)\n",
      "Processed 82/136 files (60.29%)\n",
      "Processed 83/136 files (61.03%)\n",
      "Processed 84/136 files (61.76%)\n",
      "Processed 85/136 files (62.50%)\n",
      "Processed 86/136 files (63.24%)\n",
      "Processed 87/136 files (63.97%)\n",
      "Processed 88/136 files (64.71%)\n",
      "Processed 89/136 files (65.44%)\n",
      "Processed 90/136 files (66.18%)\n",
      "Processed 91/136 files (66.91%)\n",
      "Processed 92/136 files (67.65%)\n",
      "Processed 93/136 files (68.38%)\n",
      "Processed 94/136 files (69.12%)\n",
      "Processed 95/136 files (69.85%)\n",
      "Processed 96/136 files (70.59%)\n",
      "Processed 97/136 files (71.32%)\n",
      "Processed 98/136 files (72.06%)\n",
      "Processed 99/136 files (72.79%)\n",
      "Processed 100/136 files (73.53%)\n",
      "Processed 101/136 files (74.26%)\n",
      "Processed 102/136 files (75.00%)\n",
      "Processed 103/136 files (75.74%)\n",
      "Processed 104/136 files (76.47%)\n",
      "Processed 105/136 files (77.21%)\n",
      "Processed 106/136 files (77.94%)\n",
      "Processed 107/136 files (78.68%)\n",
      "Processed 108/136 files (79.41%)\n",
      "Processed 109/136 files (80.15%)\n",
      "Processed 110/136 files (80.88%)\n",
      "Processed 111/136 files (81.62%)\n",
      "Processed 112/136 files (82.35%)\n",
      "Processed 113/136 files (83.09%)\n",
      "Processed 114/136 files (83.82%)\n",
      "Processed 115/136 files (84.56%)\n",
      "Processed 116/136 files (85.29%)\n",
      "Processed 117/136 files (86.03%)\n",
      "Processed 118/136 files (86.76%)\n",
      "Processed 119/136 files (87.50%)\n",
      "Processed 120/136 files (88.24%)\n",
      "Processed 121/136 files (88.97%)\n",
      "Processed 122/136 files (89.71%)\n",
      "Processed 123/136 files (90.44%)\n",
      "Processed 124/136 files (91.18%)\n",
      "Processed 125/136 files (91.91%)\n",
      "Processed 126/136 files (92.65%)\n",
      "Processed 127/136 files (93.38%)\n",
      "Processed 128/136 files (94.12%)\n",
      "Processed 129/136 files (94.85%)\n",
      "Processed 130/136 files (95.59%)\n",
      "Processed 131/136 files (96.32%)\n",
      "Processed 132/136 files (97.06%)\n",
      "Processed 133/136 files (97.79%)\n",
      "Processed 134/136 files (98.53%)\n",
      "Processed 135/136 files (99.26%)\n",
      "Processed 136/136 files (100.00%)\n",
      "\n",
      "âœ… All files processed. Mean MFCCs saved to mfcc_means_Control_worst.csv\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Function to extract mean MFCC features\n",
    "def extract_mean_mfcc(audio_file, n_mfcc=13, frame_length_ms=25, hop_length_ms=10):\n",
    "    \"\"\"\n",
    "    Extracts MFCC features from an audio file and computes the mean across frames.\n",
    "    Returns the mean MFCC features as a list.\n",
    "    \"\"\"\n",
    "    # Load the audio file\n",
    "    y, sr = librosa.load(audio_file, sr=None)  \n",
    "\n",
    "    # Compute hop length and FFT window size\n",
    "    hop_length = int((hop_length_ms / 1000) * sr)  \n",
    "    n_fft = int((frame_length_ms / 1000) * sr)    \n",
    "\n",
    "    # Extract MFCCs\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc, hop_length=hop_length, n_fft=n_fft)\n",
    "\n",
    "    # Compute the mean of MFCCs across time frames\n",
    "    mean_mfcc = np.mean(mfccs, axis=1)\n",
    "\n",
    "    return mean_mfcc\n",
    "\n",
    "# Function to process all audio files in a folder\n",
    "def process_audio_folder(input_folder, output_csv=\"mfcc_means.csv\"):\n",
    "    \"\"\"\n",
    "    Processes all audio files in the input folder, extracts mean MFCCs with hop_length=10ms,\n",
    "    and saves results to a CSV.\n",
    "    \"\"\"\n",
    "    # Get all audio files in the folder\n",
    "    audio_files = [f for f in os.listdir(input_folder) if f.endswith(('.wav', '.mp3'))]\n",
    "    total_files = len(audio_files)\n",
    "    \n",
    "    if total_files == 0:\n",
    "        print(\"No audio files found in the folder!\")\n",
    "        return\n",
    "    \n",
    "    # List to store results\n",
    "    mfcc_results = []\n",
    "\n",
    "    # Process each audio file\n",
    "    for i, audio_file in enumerate(audio_files):\n",
    "        audio_path = os.path.join(input_folder, audio_file)\n",
    "\n",
    "        # Extract MFCC with hop_length=10ms\n",
    "        mean_mfcc = extract_mean_mfcc(audio_path, hop_length_ms=10)\n",
    "        \n",
    "        # Append results with filename\n",
    "        mfcc_results.append([audio_file] + mean_mfcc.tolist())\n",
    "\n",
    "        # Display progress\n",
    "        print(f\"Processed {i + 1}/{total_files} files ({(i + 1) / total_files * 100:.2f}%)\")\n",
    "\n",
    "    # Define column names\n",
    "    columns = [\"Filename\"] + [f\"MFCC_{i+1}\" for i in range(len(mean_mfcc))]\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    mfcc_df = pd.DataFrame(mfcc_results, columns=columns)\n",
    "\n",
    "    # Save to CSV\n",
    "    mfcc_df.to_csv(output_csv, index=False)\n",
    "    print(f\"\\nâœ… All files processed. Mean MFCCs saved to {output_csv}\")\n",
    "\n",
    "# Define input folder containing audio files\n",
    "input_folder = r\"C:\\Users\\adity\\OneDrive\\Desktop\\Speech Sample\\Control\"  # Replace with your actual folder path\n",
    "output_file = \"mfcc_means_Control_default.csv\"  # Output file\n",
    "\n",
    "# Process all files for hop_length = 10ms and save mean MFCCs\n",
    "process_audio_folder(input_folder, output_csv=output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11d73f86-dfe8-4ed0-b265-10327a2fb03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained on merged_mfcc_best.csv - Accuracy: 0.5781\n",
      "Model trained on merged_mfcc_default.csv - Accuracy: 0.5156\n",
      "Model trained on merged_mfcc_worst.csv - Accuracy: 0.6094\n",
      "SVM applied to all CSV files successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Folder containing the CSV files\n",
    "folder_path = r\"C:\\Users\\adity\\OneDrive\\Desktop\\SVM (Default, Best, Worst)\"\n",
    "\n",
    "# Iterate through all CSV files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # Read CSV\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        df=df.drop(columns=['Filename'])  # Drop target column\n",
    "        \n",
    "        # Ensure the target column 'output' exists\n",
    "        if 'output' not in df.columns:\n",
    "            print(f\"Skipping {filename} (No 'output' column)\")\n",
    "            continue\n",
    "        \n",
    "        # Separate features (X) and target variable (y)\n",
    "        X = df.drop(columns=['output'])  # Drop target column\n",
    "        y = df['output']\n",
    "\n",
    "        # Handle missing values (fill with mean)\n",
    "        # X = X.fillna(X.mean())\n",
    "\n",
    "        # Standardize features\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "        # Split data into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.25, random_state=42)\n",
    "\n",
    "        # Train SVM model\n",
    "        model = SVC(kernel='poly')  # Use RBF kernel for non-linear classification\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict and evaluate\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        print(f\"Model trained on {filename} - Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "print(\"SVM applied to all CSV files successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15061255-4537-4b0e-8b71-ab465ba06ccf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
